{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "import re \n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>descr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, descr]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('corpus.csv')\n",
    "df = df2.drop(['story', 'url'], axis=1)\n",
    "df = df.drop_duplicates()\n",
    "df.loc[lambda df: df['title']==\"Video Eurosport\"]\n",
    "df = df.drop([1308])\n",
    "df.loc[lambda df: df['title']==\"Video Eurosport\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "def tokenize(string):\n",
    "    string = re.sub(r'[^\\w\\s]', ' ',  string)\n",
    "    tokens = string.lower().split()\n",
    "    words = [t for t in tokens if len(t) > 2]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198304, 16908)\n",
      "16908\n",
      "(97872, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>descr</th>\n",
       "      <th>title_idx</th>\n",
       "      <th>descr_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Русские биатлонистки покорили спринт на Универ...</td>\n",
       "      <td>Это был не чемпионат России.</td>\n",
       "      <td>[1307, 4471, 7429, 9764, 12504, 13769, 15099]</td>\n",
       "      <td>[12385, 16129, 16739]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Россия обыграла США на Универсиаде и возглавил...</td>\n",
       "      <td>Красивая победа «Красной машины».</td>\n",
       "      <td>[2319, 3349, 8848, 12400, 14222, 15099]</td>\n",
       "      <td>[6260, 6279, 7329, 10045]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>«Аякс» не проигрывает, если открывает счет. 6 ...</td>\n",
       "      <td>Выдающаяся статистика сказочного матча.</td>\n",
       "      <td>[1018, 9317, 11457, 11806, 12059, 14211, 15322]</td>\n",
       "      <td>[7295, 13928]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Krone: в Австрии арестовали лыжника Дюрра. Он ...</td>\n",
       "      <td>Попался сам – пусть попадутся и другие.</td>\n",
       "      <td>[422, 4051, 6906, 10585]</td>\n",
       "      <td>[4151, 10633, 11659]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Французская конькобежка подрезала кореянку, и ...</td>\n",
       "      <td>Женский финал на универсиаде в Красноярске пол...</td>\n",
       "      <td>[2277, 6135, 12140, 15651]</td>\n",
       "      <td>[4362, 10546, 15099, 15461]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Русские биатлонистки покорили спринт на Универ...   \n",
       "1  Россия обыграла США на Универсиаде и возглавил...   \n",
       "2  «Аякс» не проигрывает, если открывает счет. 6 ...   \n",
       "4  Krone: в Австрии арестовали лыжника Дюрра. Он ...   \n",
       "5  Французская конькобежка подрезала кореянку, и ...   \n",
       "\n",
       "                                               descr  \\\n",
       "0                       Это был не чемпионат России.   \n",
       "1                  Красивая победа «Красной машины».   \n",
       "2            Выдающаяся статистика сказочного матча.   \n",
       "4            Попался сам – пусть попадутся и другие.   \n",
       "5  Женский финал на универсиаде в Красноярске пол...   \n",
       "\n",
       "                                         title_idx  \\\n",
       "0    [1307, 4471, 7429, 9764, 12504, 13769, 15099]   \n",
       "1          [2319, 3349, 8848, 12400, 14222, 15099]   \n",
       "2  [1018, 9317, 11457, 11806, 12059, 14211, 15322]   \n",
       "4                         [422, 4051, 6906, 10585]   \n",
       "5                       [2277, 6135, 12140, 15651]   \n",
       "\n",
       "                     descr_idx  \n",
       "0        [12385, 16129, 16739]  \n",
       "1    [6260, 6279, 7329, 10045]  \n",
       "2                [7295, 13928]  \n",
       "4         [4151, 10633, 11659]  \n",
       "5  [4362, 10546, 15099, 15461]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. токенизируем тексты с опциональной лемматизацией\n",
    "# 3. строим словарь из слов, которые встречаются достаточно часто\n",
    "# 4. представляем каждый текст как набор индексов слов в словаре\n",
    "\n",
    "corpus = pd.concat([df['title'], df['descr']])\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(\n",
    "    min_df=10,\n",
    "    max_df = 0.8,\n",
    "    stop_words = stopwords.words('russian'),\n",
    "    tokenizer=tokenize)\n",
    "\n",
    "transformed_corpus = vectorizer.fit_transform(corpus)\n",
    "print(transformed_corpus.shape)\n",
    "\n",
    "vocab = vectorizer.vocabulary_\n",
    "num_words = len(vocab)\n",
    "print(num_words)\n",
    "\n",
    "titles = vectorizer.transform(df['title'])\n",
    "descrs = vectorizer.transform(df['descr'])\n",
    "df['title_idx'] = [i.indices for i in titles]\n",
    "df['descr_idx'] = [i.indices for i in descrs]\n",
    "df=df[df['title_idx'].map(len) !=0]\n",
    "df=df[df['descr_idx'].map(len) !=0]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. инициализируем для каждого слова случайный вектор некоторой длины\n",
    "def initialize(matrix_size = 128):\n",
    "    matrix = np.array(np.random.normal(0.0001, 0.00001, matrix_size * num_words))\n",
    "    matrix = np.reshape(matrix, newshape=(num_words, matrix_size))\n",
    "    vt = np.zeros(matrix.shape, dtype=np.float16)\n",
    "    return matrix, vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7. представляем каждый текст как результат функции агрегации avg, применённой к векторам составляющих его слов\n",
    "\n",
    "def get_vector(text_idx):\n",
    "    return np.mean(matrix[text_idx], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 8. считаем функцию потерь warp\n",
    "\n",
    "def warp(data, right_scalar, wrong_scalar, gamma = 1.0):\n",
    "    loss = gamma - right_scalar + wrong_scalar\n",
    "    if (loss > 0):\n",
    "        return loss\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 9. обновляем параметры модели\n",
    "\n",
    "def update_sgdm(idx, gradient, vt, gamma=0.9, learning_rate=0.01):\n",
    "    vt[idx] = gamma * vt[idx] + learning_rate * gradient\n",
    "    matrix[idx] -= vt[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10. убедиться что параметры модели удовлетворяют ограничениям unitnorm\n",
    "\n",
    "def unitnorm(matrix):\n",
    "    for i in range(len(matrix)):\n",
    "        norm = np.sqrt(np.sum(matrix[i] ** 2))\n",
    "        if (round(norm, 3) != 1):\n",
    "            matrix[i] /= norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# метрика качества модели\n",
    "\n",
    "def get_dist(v1, v2):\n",
    "    return 1 - np.dot(v1, np.transpose(v2)) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "  \n",
    "def recall(data, k = 10):\n",
    "    n_test = len(data)\n",
    "    recall = 0\n",
    "    descr_emb = [get_vector(data.iloc[[i]]['descr_idx'].values[0]) for i in range(n_test)]\n",
    "\n",
    "    for i in range(n_test):\n",
    "        title_emb = get_vector(data.iloc[[i]]['title_idx'].values[0])     \n",
    "        dist_arr = []\n",
    "        for i_1 in range(n_test):\n",
    "            dist_arr.append(get_dist(title_emb, descr_emb[i_1]))\n",
    "\n",
    "        sort_dist_arr = np.sort(dist_arr)\n",
    "        if dist_arr[i] <= sort_dist_arr[k-1]:\n",
    "            recall += 1\n",
    "\n",
    "    return recall / n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96808 1000\n"
     ]
    }
   ],
   "source": [
    "train_data = df[:96808]\n",
    "test_data = df[96808:97808]\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "def train(train_data, test_data, n_epochs, vt, gamma, alpha, check_step=1000):\n",
    "    for epoch in range(n_epochs):\n",
    "        t1 = time.process_time()\n",
    "        seq = np.random.permutation(len(train_data))\n",
    "        n_steps = 0\n",
    "        for i in seq:\n",
    "            sample = train_data.iloc[[i]]\n",
    "            title = sample['title_idx'].values[0]\n",
    "            descr = sample['descr_idx'].values[0]\n",
    "            first_title_vector = get_vector(title)\n",
    "            first_descr_vector = get_vector(descr)    \n",
    "\n",
    "            random_index = np.random.randint(len(train_data))\n",
    "            while (random_index == i):\n",
    "                random_index = np.random.randint(len(train_data))\n",
    "\n",
    "            random_descr = train_data.iloc[[random_index]]['descr_idx'].values[0]\n",
    "            random_descr_vector = get_vector(random_descr)\n",
    "\n",
    "            right_scalar = np.dot(first_title_vector, first_descr_vector)\n",
    "            wrong_scalar = np.dot(first_title_vector, random_descr_vector)\n",
    "            loss = warp(train_data, right_scalar, wrong_scalar, i)\n",
    "            if not loss:\n",
    "                continue          \n",
    "\n",
    "            gradients = ((first_descr_vector - random_descr_vector), first_title_vector, np.negative(first_title_vector))\n",
    "            \n",
    "            for i, g in zip([title, descr, random_descr], gradients):\n",
    "                update_sgdm(i, g, vt, gamma, alpha)\n",
    "            n_steps += 1\n",
    "            if n_steps%50 == 49:\n",
    "                sys.stdout.write(\"\\rTraining: %f%%\" % (100*(n_steps+1)/len(seq)))\n",
    "                sys.stdout.flush()\n",
    "            if n_steps % check_step == 0:\n",
    "                unitnorm(matrix)\n",
    "        test_recall = recall(test_data)\n",
    "        t = time.process_time() - t1\n",
    "        print(\"Epoch {:>2} : recall = {:>5}%  time = {:>4}s\".format(epoch, round(test_recall, 2), round(t,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# близкие слова\n",
    "\n",
    "def knn(ind, k=10):\n",
    "    dist_arr = {}\n",
    "\n",
    "    for i in range(0, len(matrix)):\n",
    "        dist_arr[i] = get_dist(matrix[ind], matrix[i])\n",
    "\n",
    "    sorted_embs = sorted(dist_arr.items(), key=lambda kv: kv[1])[:k]\n",
    "    for emb in sorted_embs:\n",
    "        if emb[0] != ind:\n",
    "            print(\"\\t\" + dict(zip(vocab.values(), vocab.keys()))[emb[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 99.991736%Epoch 0 : recall =  0.21%  time = 203.172s\n",
      "Training: 99.991736%Epoch 1 : recall =  0.21%  time = 187.691s\n",
      "Training: 99.991736%Epoch 2 : recall =  0.23%  time = 191.442s\n",
      "Training: 99.991736%Epoch 3 : recall =  0.24%  time = 190.892s\n",
      "Training: 99.991736%Epoch 4 : recall =  0.26%  time = 194.739s\n",
      "Training: 99.991736%Epoch 5 : recall =  0.26%  time = 198.231s\n",
      "Training: 99.991736%Epoch 6 : recall =  0.26%  time = 195.673s\n",
      "Training: 99.991736%Epoch 7 : recall =  0.28%  time = 193.941s\n",
      "Training: 99.991736%Epoch 8 : recall =  0.31%  time = 197.587s\n",
      "Training: 99.991736%Epoch 9 : recall =  0.31%  time = 195.387s\n"
     ]
    }
   ],
   "source": [
    "matrix, vt = initialize(128)\n",
    "train(train_data, test_data, 10, vt, 0.99, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tкриштиану\n",
      "\tбарселоны\n",
      "\tмесси\n",
      "\tреала\n",
      "\tтренер\n",
      "\tжозе\n",
      "\tмадридского\n",
      "\tмоуринью\n",
      "\tглавный\n"
     ]
    }
   ],
   "source": [
    "knn(vocab.get(\"роналду\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tбарселона\n",
      "\tхесе\n",
      "\tдепортиво\n",
      "\tатлетику\n",
      "\tгранады\n",
      "\tкоруньи\n",
      "\tбарселону\n",
      "\tэспаньола\n",
      "\tкаталонцам\n"
     ]
    }
   ],
   "source": [
    "knn(vocab.get(\"реал\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tфорварды\n",
      "\tовечкин\n",
      "\tварламовым\n",
      "\tхоккеистов\n",
      "\tголосование\n",
      "\tхоккей\n",
      "\tнападающие\n",
      "\tмарков\n",
      "\tхоккее\n"
     ]
    }
   ],
   "source": [
    "knn(vocab.get(\"коньки\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
